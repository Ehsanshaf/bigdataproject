---
title: "xgboost_numero1"
author: "Vera"
date: "14 7 2017"
output: html_document
---

Libraries:
```{r, echo = F}
library(data.table)
library(dplyr)
library(tidyr)
library(xgboost)
library(ggplot2)

vh <- function(x){View(head(x,25))}
```


# Prep: 

Loading Data:
* Aisles and Department data just contain the name belonging to the number; not needed here as xgboost needs hot encoded or label encoded(numeric) features. 
* op_prior and op_train contain product information from training and test people (! train and test people are not the same ones) -> features: order_id, product_id, add_to_cart_order, reordered(1,2)
* orders contains some information about an order for train, test and prior orders. With this dataset test useres can be identified. Features: order_id, user_id, eval_set, order_number, dow, hours and days since last order.
* products contains informarion about the product -> aisle and department information

```{r}
aisles <- read.csv(unz("/home/Vera_Weidmann/Supermarket/00_Data/aisles.csv.zip", "aisles.csv"), stringsAsFactors = FALSE)

departments <- read.csv(unz("/home/Vera_Weidmann/Supermarket/00_Data/departments.csv.zip", "departments.csv"), stringsAsFactors = FALSE)

op_prior <- read.csv(unz("/home/Vera_Weidmann/Supermarket/00_Data/order_products__prior.csv.zip", "order_products__prior.csv"), stringsAsFactors = FALSE)

op_train <- read.csv(unz("/home/Vera_Weidmann/Supermarket/00_Data/order_products__train.csv.zip", "order_products__train.csv"), stringsAsFactors = FALSE)

orders <- read.csv(unz("/home/Vera_Weidmann/Supermarket/00_Data/orders.csv.zip", "orders.csv"), stringsAsFactors = FALSE)
vh(orders)

products <- read.csv(unz("/home/Vera_Weidmann/Supermarket/00_Data/products.csv.zip", "products.csv"), stringsAsFactors = FALSE)
```

# Reshape data:
```{r}
aisles$aisle <- as.factor(aisles$aisle)
departments$department <- as.factor(departments$department)
orders$eval_set <- as.factor(orders$eval_set)
products$product_name <- as.factor(products$product_name)

products <- products %>% 
  inner_join(aisles) %>% inner_join(departments) %>% 
  select(-aisle_id, -department_id)
rm(aisles, departments)

#merge user_id to op_train
op_train$user_id <- orders$user_id[match(op_train$order_id, orders$order_id)]

#contains just prior order information -> test and train orders are not included!!
orders_products <- orders %>% inner_join(op_prior, by = "order_id")
vh(orders_products)
sum(is.na(orders_products$product_id))

#orders_products %>% filter(order_id == 1187899)
#orders_products %>% filter(eval_set == "train") # 0
```

# Product Features:
```{r}
#contains just the product and how often it was ordered, reordered and so on.
prd <- orders_products %>% #just prior information
  arrange(user_id, order_number, product_id) %>%
  group_by(user_id, product_id) %>%
  mutate(product_time = row_number()) %>%
  ungroup() %>%
  group_by(product_id) %>%
  summarise(
    prod_orders = n(), #count products
    prod_reorders = sum(reordered), #count products reordered
    prod_first_orders = sum(product_time == 1), #product bought first time
    prod_second_orders = sum(product_time == 2) #product bought second time
  )

#vh(prd)

prd$prod_reorder_probability <- prd$prod_second_orders / prd$prod_first_orders
prd$prod_reorder_times <- 1 + prd$prod_reorders / prd$prod_first_orders
prd$prod_reorder_ratio <- prd$prod_reorders / prd$prod_orders

prd <- prd %>% select(-prod_reorders, -prod_first_orders, -prod_second_orders)
```

# User Features:
```{r}
#prior orders -> test and train peops
users <- orders %>%
  filter(eval_set == "prior") %>%
  group_by(user_id) %>%
  summarise(
    user_orders = max(order_number), #max order number
    user_period = sum(days_since_prior_order, na.rm = T), #days since first order
    user_mean_days_since_prior = mean(days_since_prior_order, na.rm = T) #average time between orders
  )

# users2 <- orders_products %>%
#   group_by(user_id) %>%
#   summarise(
#     user_orders = max(order_number), #max order number
#     user_period = sum(days_since_prior_order, na.rm = T), #days since first order
#     user_mean_days_since_prior = mean(days_since_prior_order, na.rm = T) #average time between orders
#   )
#differences??? 
#vh(users)

#prior orders
us <- orders_products %>%
  group_by(user_id) %>%
  summarise(
    user_total_products = n(),
    user_reorder_ratio = sum(reordered == 1) / sum(order_number > 1),
    user_distinct_products = n_distinct(product_id)
  )
#vh(us)


users <- users %>% inner_join(us)
users$user_average_basket <- users$user_total_products / users$user_orders

#test and train information for getting info about time was gone between last order and now
us <- orders %>%
  filter(eval_set != "prior") %>%
  select(user_id, order_id, eval_set,
         time_since_last_order = days_since_prior_order)

users <- users %>% inner_join(us)

vh(users)
```


Visulalistazions:
```{r}
plot(users$user_orders[1:20]~ users$user_id[1:20])
plot(orders_products$eval_set)
```

# Create training dataset:
```{r}
orders_products %>% filter(eval_set == "test" | eval_set == "train") # 0 -> just prior

#trained on prior information
data <- orders_products %>%
  group_by(user_id, product_id) %>% 
  summarise(
    up_orders = n(),
    up_first_order = min(order_number),
    up_last_order = max(order_number),
    up_average_cart_position = mean(add_to_cart_order))

#rm(orders_products, orders)

#join new features about user and products
data <- data %>% 
  inner_join(prd, by = "product_id") %>%
  inner_join(users, by = "user_id")

data$up_order_rate <- data$up_orders / data$user_orders
data$up_orders_since_last_order <- data$user_orders - data$up_last_order
data$up_order_rate_since_first_order <- data$up_orders / (data$user_orders - data$up_first_order + 1)

#join column reordered (lable variable)
data <- data %>% 
  left_join(op_train %>% select(user_id, product_id, reordered), 
            by = c("user_id", "product_id"))

vh(data)

sum(is.na(data$reordered)) # not reordered
data %>% filter (reordered < 1) # contains just 1 for reordered
```

Split data into train and test dataset:
```{r}
train <- as.data.frame(data[data$eval_set == "train",])
#remove some columns
train$eval_set <- NULL
train$user_id <- NULL
train$product_id <- NULL
train$order_id <- NULL
train$reordered[is.na(train$reordered)] <- 0 #reordered Nas == 0
save(train, file = "train_xboost_vera.rda")

test <- as.data.frame(data[data$eval_set == "test",])
test$eval_set <- NULL
test$user_id <- NULL
test$reordered <- NULL
save(test, file = "test_xboost_vera.rda")
#hint: test has also some other features as order_id and product_id, on which nothing is predicted. But we can still assign the predictions to the user and order. 
```

# CV to find the best params:

# Fit model
```{r}
params <- list(
  "objective"           = "reg:logistic",
  "eval_metric"         = "logloss",
  "eta"                 = 0.1,
  "max_depth"           = 6,
  "min_child_weight"    = 10,
  "gamma"               = 0.70,
  "subsample"           = 0.76,
  "colsample_bytree"    = 0.95,
  "alpha"               = 2e-05,
  "lambda"              = 10
)
```

```{r}
subtrain <- train #%>% sample_frac(0.1) #train just on a fraction due to computation probs
X <- xgb.DMatrix(as.matrix(subtrain %>% select(-reordered)), label = subtrain$reordered) #create xgb matrix
model <- xgboost(data = X, 
                 params = params, 
                 nrounds = 200,
                 nthread = 16
                 )

#importance <- xgb.importance(colnames(X), model = model)
#xgb.ggplot.importance(importance)
```

* 10% subset, rounds = 80, min logloss = 0.242989 -> Leaderboard: 0.3792617
* all data (train), rounds = 80, nthread = 16, min logloss = 0.244848
* all data (train), rounds = 200, nthread = 16, min logloss = 0.243583 -> Leaderboard: 0.3815433
* try 1000 rounds


# Predict on model: 
```{r}
Y <- xgb.DMatrix(as.matrix(test %>% select(-order_id, -product_id)))#here dont select order and product id as we dont want to predict on them
test$reordered <- predict(model, Y)
```

Cutting point:
* > 21 % -> Kaggle leaderboard score: 0.3792617, 0.3815433
* cutoff point -> Leaderboard 0.15 (bad!!!)
```{r}
#approach 1:
#test$reordered <- (test$reordered > 0.21) * 1
```

cutoff lookup:
```{r}
#approach 2:
load("/home/Max_Philipp/bigdataproject/cutofflookup.rda")

lookup <- lookup %>% group_by(user_id) %>% mutate(cutoff=max(round((user_reorder_ratio+(1-user_reorder_ratio)/2)*user_average_basket),1))
```

```{r, really bad}
# vh(test)
# vh(submission)
# #Submission approach 2:
# 
# 
# submission <- test %>% 
#   inner_join(lookup, by="order_id")
#   
# submission <- submission %>% 
#   arrange(user_id,-reordered)%>% 
#   group_by(user_id) %>% 
#   mutate(index=row_number()) %>% 
#   filter(index<=cutoff) %>% 
#   ungroup()
# 
# submission <- submission %>% 
#   select(order_id,product_id) %>%
#   group_by(order_id) %>% 
#   summarise(products = paste(product_id, collapse = " "))
# 
# 
# #some missing orders (75000 - 71044) # warum??
# missing <- data.frame(
#   order_id = unique(test$order_id[!test$order_id %in% submission$order_id]),
#   products = "None"
# )
# submission <- submission %>% bind_rows(missing) %>% arrange(order_id)
# write.csv(submission, file = "xgboost_numero1_submission_3_basketcut.csv", row.names = F)

```

# Submission:
```{r}
submission <- test %>%
  filter(reordered == 1) %>% #select just products which are predicted as reordered
  group_by(order_id) %>%
  summarise(
    products = paste(product_id, collapse = " ")
  )

#some missing orders (75000 - 71044) # warum??
missing <- data.frame(
  order_id = unique(test$order_id[!test$order_id %in% submission$order_id]),
  products = "None"
)

submission <- submission %>% bind_rows(missing) %>% arrange(order_id)
write.csv(submission, file = "xgboost_numero1_submission_3.csv", row.names = F)
```

# Improvement Ideas:

* CV laufen lassen / adjust xgboost model
* Dont train on the train users
* Scale features
* PCA ?
* cutting point Ã¤ndern -> scoring function and optimize on training data